{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing 1: Loading, Stacking, Imputing \n",
    "\n",
    "## Introduction\n",
    "\n",
    "Data preprocessing is a crucial step in any machine learning workflow. Just as traditional methods like OLS regression are sensitive to outliers and data quirks, modern machine learning approaches can be equally affected by data distributions, missing values, and other irregularities.\n",
    "\n",
    "In this notebook, we will explore how to prepare financial data for machine learning models. Specifically, we'll predict the 12-month average return of companies using historical financial data. We'll work with time-series financial data containing information on thousands of companies.\n",
    "\n",
    "### Key Steps We'll Cover:\n",
    "\n",
    "1. **Problem Formulation**: Framing investment prediction as a machine learning problem\n",
    "2. **Stacking Time-Series Data**: Removing long-term temporal dependencies to simplify analysis\n",
    "3. **Calculating Average Returns**: Using geometric calculations over the forecasting period\n",
    "4. **Incorporating Index Data**: Benchmarking and normalizing returns\n",
    "5. **Feature Extraction**: Obtaining independent variables from the data\n",
    "6. **Handling Missing Values**: Implementing KNN imputation with hyperparameter tuning\n",
    "\n",
    "Let's start by loading the necessary libraries and exploring our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set plot styles for better visualization\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's first examine what files are available in our `Data` folder to understand what information we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the Data directory\n",
    "files = os.listdir(\"data\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple CSV files containing various financial metrics for companies. The file `TotalReturn_BaseCCY.csv` contains monthly return data for thousands of companies, which is our primary dataset. Let's take a closer look at it.\n",
    "\n",
    "First, we need a helper function to standardize column names across our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_convert(df):\n",
    "    \"\"\"\n",
    "    Convert date columns from MM/DD/YYYY format to YYYY-MM-DD format for consistency.\n",
    "    Non-date columns (NAME, TICKER, SECTOR, COUNTRY) remain unchanged.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with date columns to convert\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with converted column names\n",
    "    \"\"\"\n",
    "    cols_static = ['NAME', 'TICKER', 'SECTOR', 'COUNTRY']\n",
    "    cols_date_orig = [x for x in df.columns if x not in cols_static]\n",
    "    \n",
    "    # Convert MM/DD/YYYY to YYYY-MM-DD format\n",
    "    cols_date = [col[-4:] + '-' + col[:2] + '-' + col[3:5] for col in cols_date_orig]\n",
    "    \n",
    "    # Create the new column list\n",
    "    new_cols = cols_static + cols_date\n",
    "    df.columns = new_cols\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the return data and convert column names\n",
    "df = pd.read_csv('Data/TotalReturn_BaseCCY.csv')\n",
    "df = cols_convert(df)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "nrows, ncols = df.shape\n",
    "print(f\"Number of companies (rows): {nrows}\")\n",
    "print(f\"Number of columns: {ncols}\")\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data Structure\n",
    "\n",
    "Let's interpret the columns in our dataset:\n",
    "\n",
    "- **NAME**: Company name\n",
    "- **TICKER**: A unique identifier for each company\n",
    "- **SECTOR**: The business sector of the company (e.g., Financials, Technology)\n",
    "- **COUNTRY**: Country where the company operates\n",
    "- **Date columns (YYYY-MM-DD)**: Monthly returns for each company\n",
    "\n",
    "For example, if a company shows a value of 0.045730 for 2000-10-31, it means the company had a return of approximately 4.57% for the month ending on that date (from 2000-09-30 to 2000-10-31).\n",
    "\n",
    "The dataset contains monthly returns for over 6,000 companies from 2000-01-31 to 2020-09-20. Other CSV files in the `Data` folder follow a similar format but contain different financial metrics for the same companies.\n",
    "\n",
    "## 1. Problem Formulation\n",
    "\n",
    "Our goal is to develop a machine learning model that can predict the average 12-month return of companies. We'll use a 3-year sliding window **without overlap** as our approach:\n",
    "\n",
    "- For predicting 2004 returns, we'll use data from 2001, 2002, and 2003 as features\n",
    "- For predicting 2007 returns, we'll use data from 2004, 2005, and 2006 as features\n",
    "- And so on...\n",
    "\n",
    "For each feature (like ROE - Return on Equity), we'll use the values from the last month of each year in our 3-year window. For example, to predict the 2004 returns, we would use ROE values from 2001-12-31, 2002-12-31, and 2003-12-31.\n",
    "\n",
    "Let's start by filtering our data to include only the years we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target years for return prediction\n",
    "target_years = ['2004', '2007', '2010', '2013', '2016', '2019']\n",
    "\n",
    "# Drop columns for years we're not using for target predictions\n",
    "for col in df.columns[4:]:\n",
    "    year = col[:4]\n",
    "    if year not in target_years:\n",
    "        df.drop(col, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stacking Time-Series Data\n",
    "\n",
    "In our current data format, company returns are organized horizontally across time (each row is a company, and columns represent different time periods). To simplify our analysis and avoid modeling long-term time dependencies, we'll reorganize or \"stack\" the data.\n",
    "\n",
    "This transformation helps us:\n",
    "- Focus on yearly patterns rather than long-term trends\n",
    "- Simplify the calculation of average returns\n",
    "- Create a more suitable format for machine learning models\n",
    "\n",
    "The stacking process transforms the data from a wide format (many columns) to a taller format (more rows), where each company will appear multiple times (once for each target year). We'll add a 'YEAR' column to track which year's data we're looking at.\n",
    "\n",
    "Here's the transformation we'll apply:\n",
    "\n",
    "![Stacking Diagram](Images/stacking_diagram.png)\n",
    "\n",
    "Now let's implement this stacking operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_data(df):\n",
    "    \"\"\"\n",
    "    Stack time-series data from wide to tall format.\n",
    "    \n",
    "    For each year, extracts 12 months of returns and adds a YEAR column.\n",
    "    Static columns (NAME, TICKER, SECTOR, COUNTRY) are preserved.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with time-series data in wide format\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Stacked DataFrame with month columns and YEAR identifier\n",
    "    \"\"\"\n",
    "    # Define the columns for the stacked dataframe\n",
    "    columns = [\n",
    "        'NAME', 'TICKER', 'SECTOR', 'COUNTRY',\n",
    "        'DEC', 'NOV', 'OCT', 'SEP', 'AUG', 'JUL', \n",
    "        'JUN', 'MAY', 'APR', 'MAR', 'FEB', 'JAN',\n",
    "        'YEAR'\n",
    "    ]\n",
    "    \n",
    "    # Initialize an empty DataFrame with the column structure\n",
    "    stacked_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Process the data year by year\n",
    "    i = 4  # Start after the static columns (NAME, TICKER, SECTOR, COUNTRY)\n",
    "    while i < df.shape[1]:\n",
    "        # Extract static columns and 12 months of returns\n",
    "        subframe = df[list(df.columns[0:4]) + list(df.columns[i:i+12])].copy()\n",
    "        \n",
    "        # Add the year column\n",
    "        subframe['YEAR'] = int(df.columns[i][:4])\n",
    "        \n",
    "        # Rename columns to match our stacked format\n",
    "        subframe.columns = stacked_df.columns\n",
    "        \n",
    "        # Append to our stacked DataFrame\n",
    "        stacked_df = pd.concat([stacked_df, subframe], ignore_index=True)\n",
    "        \n",
    "        # Move to the next year (next 12 columns)\n",
    "        i += 12\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    stacked_df = stacked_df.dropna(axis=0)\n",
    "    \n",
    "    # Reset the index for cleaner output\n",
    "    stacked_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the data\n",
    "X = stack_data(df)\n",
    "\n",
    "# Display the first few rows of the stacked data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacked format gives us a clearer view of monthly returns for each company in each target year. Now each row represents a company's performance over a single year.\n",
    "\n",
    "### Handling Outliers in Return Data\n",
    "\n",
    "Before calculating average returns, we should examine and handle outliers in our data. Extreme return values could significantly skew our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify extreme values in monthly returns\n",
    "months = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
    "\n",
    "# Create a DataFrame to store min and max values for each month\n",
    "extremes = pd.DataFrame({\n",
    "    \"max\"       : X[months].max(),                     \n",
    "    \"max_name\"  : list(X.loc[X[months].idxmax()]['NAME']), \n",
    "    \"max_year\"  : list(X.loc[X[months].idxmax()]['YEAR']), \n",
    "    \"min\"       : list(X[months].min()),                     \n",
    "    \"min_name\"  : list(X.loc[X[months].idxmin()]['NAME']), \n",
    "    \"min_year\"  : list(X.loc[X[months].idxmin()]['YEAR']),\n",
    "})\n",
    "\n",
    "extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some extreme values in our data. For example, one company shows a return of 389.91 (nearly 39,000%) for February 2004, which is likely an outlier or data error. Similarly, there are extremely negative returns that could skew our analysis.\n",
    "\n",
    "To handle these outliers, we'll use winsorization - a technique that caps extreme values at a specific percentile (in this case, the 5th and 95th percentiles). We'll apply this transformation separately for each year to maintain the temporal characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_stacked_data(df, lower_percentile=0.05, upper_percentile=0.95):\n",
    "    \"\"\"\n",
    "    Clip extreme values in monthly return data to reduce the impact of outliers.\n",
    "    \n",
    "    For each year separately, caps values at the specified percentiles.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Stacked DataFrame with monthly return data\n",
    "    lower_percentile : float, default 0.05\n",
    "        Values below this percentile will be clipped\n",
    "    upper_percentile : float, default 0.95\n",
    "        Values above this percentile will be clipped\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with winsorized values\n",
    "    \"\"\"\n",
    "    months = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
    "    years = df['YEAR'].unique()\n",
    "    \n",
    "    # Process each year separately\n",
    "    for year in years:      \n",
    "        # Get data for this year\n",
    "        year_data = df.loc[df['YEAR'] == year, months]\n",
    "        \n",
    "        # Calculate percentile thresholds\n",
    "        upper_limits = year_data.quantile(upper_percentile)\n",
    "        lower_limits = year_data.quantile(lower_percentile)\n",
    "        \n",
    "        # Clip values\n",
    "        year_data = year_data.clip(lower=lower_limits, upper=upper_limits, axis=1)\n",
    "        \n",
    "        # Update the original DataFrame\n",
    "        df.loc[df['YEAR'] == year, months] = year_data\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply winsorization to handle outliers\n",
    "X = winsorize_stacked_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculating Average Returns\n",
    "\n",
    "Now that we've cleaned our monthly return data, we can calculate the average annual return for each company. For financial returns, we'll use the geometric mean rather than the arithmetic mean, as it provides a more accurate representation of investment returns over time.\n",
    "\n",
    "The standard geometric mean formula would be:\n",
    "$$r = \\prod_{i=1}^{12} r_i$$\n",
    "\n",
    "Where $r_i$ is the return for the $i$-th month. However, this approach has a critical limitation: if any monthly return is negative, the overall result would be negative regardless of other months' performance.\n",
    "\n",
    "A more appropriate formula for financial returns is:\n",
    "$$r = \\prod_{i=1}^{12} (1 + r_i) - 1$$\n",
    "\n",
    "This formula effectively calculates the compound growth rate over the year. Since none of our returns are less than -1 (after winsorization), $(1 + r_i)$ will always be positive, avoiding the issue of misrepresenting the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_geometric_mean(df):\n",
    "    \"\"\"\n",
    "    Calculate the geometric mean of monthly returns for each company.\n",
    "    \n",
    "    Uses the formula: ((1+r₁)*(1+r₂)*...*(1+r₁₂))^(1/12) - 1\n",
    "    This represents the compound annual growth rate.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with monthly return data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with average annual returns\n",
    "    \"\"\"\n",
    "    months = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
    "    \n",
    "    # Calculate compound return: Π(1+rᵢ) - 1\n",
    "    df[\"AVERAGE RETURN\"] = (df[months] + 1).product(axis=1) - 1\n",
    "    \n",
    "    # Drop the individual monthly returns\n",
    "    df = df.drop(months, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate geometric mean returns\n",
    "X = calculate_geometric_mean(X)\n",
    "\n",
    "# Display the first few rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Index Data for Benchmarking and Normalization\n",
    "\n",
    "In investment analysis, returns are typically benchmarked against a reference index to provide context and enable more meaningful comparisons. We'll use the MSCI All Countries World Index (ACWI), which includes both emerging and developed market stocks.\n",
    "\n",
    "This benchmarking serves two important purposes:\n",
    "1. It measures performance relative to the broader market\n",
    "2. It normalizes returns, reducing the impact of market-wide movements\n",
    "\n",
    "The MSCI ACWI is a total return index, accounting for both price changes and dividend payments, adjusted for common taxes (\"net return\"). Let's load the index data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MSCI ACWI index data\n",
    "index = pd.read_csv(\"index/INDEX.csv\", skiprows=8)\n",
    "\n",
    "# Remove non-numeric columns\n",
    "index = index.drop([\"NAME\", \"TICKER\", \"SECTOR\", \"COUNTRY\"], axis=1) \n",
    "\n",
    "# Display the first few rows\n",
    "index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll adjust the company returns using the index data. The formula for this adjustment is:\n",
    "\n",
    "$$r_{adjusted} = \\frac{1 + r_{company}}{1 + r_{index}} - 1$$\n",
    "\n",
    "Where $r_{company}$ is the company's return for a given month, and $r_{index}$ is the index return for the same month.\n",
    "\n",
    "This adjustment tells us how a company performed relative to the market. For example, if a company's return was 5% in a month when the index returned 3%, the adjusted return would be approximately 1.94%, indicating the company outperformed the market by that amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original return data for adjustment\n",
    "returns = pd.read_csv(\"Data/TotalReturn_BaseCCY.csv\")\n",
    "returns = cols_convert(returns)\n",
    "\n",
    "# The global MSCI data is missing values for the year 2000, so we remove those years\n",
    "returns = returns[list(returns.columns[:-12])]\n",
    "\n",
    "# Adjust column names in the index data to match the returns data\n",
    "index.columns = returns.columns[4:]\n",
    "\n",
    "# Calculate the adjusted returns: (1+company_return)/(1+index_return) - 1\n",
    "returns[returns.columns[4:]] += 1  # Add 1 to company returns\n",
    "returns[returns.columns[4:]] = returns[returns.columns[4:]].divide(1 + index.iloc[0], axis=1)  # Divide by (1+index)\n",
    "returns[returns.columns[4:]] -= 1  # Subtract 1 to get adjusted returns\n",
    "\n",
    "# Filter for our target years\n",
    "for col in returns.columns[4:]:\n",
    "    year = col[:4]\n",
    "    if year not in target_years:\n",
    "        returns.drop(col, inplace=True, axis=1)\n",
    "        \n",
    "# Display the first few rows of adjusted returns\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's process these index-adjusted returns the same way we did with the original returns: stacking, winsorizing, and calculating geometric means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the adjusted returns\n",
    "returns = stack_data(returns)\n",
    "returns = winsorize_stacked_data(returns)\n",
    "returns = calculate_geometric_mean(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extracting Independent Variables (Features)\n",
    "\n",
    "Now that we have our target variable (average annual returns), we need to extract features from our other financial datasets. As mentioned earlier, for each target year, we'll use data from the three preceding years as features.\n",
    "\n",
    "For example, to predict returns in 2004, we'll use financial metrics from 2001-12-31, 2002-12-31, and 2003-12-31. Let's implement this feature extraction process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df, file_list):\n",
    "    \"\"\"\n",
    "    Extract features from multiple financial data files for predictive modeling.\n",
    "    \n",
    "    For each target year, extracts values from the previous 3 years (12, 24, and 36 months prior).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Target DataFrame with YEAR and TICKER columns\n",
    "    file_list : list\n",
    "        List of file names to extract features from\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with original data plus extracted features\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Get unique years in the dataset\n",
    "    years = set(result_df.YEAR) \n",
    "    \n",
    "    # Process each file\n",
    "    for file in file_list:\n",
    "        print(f\"Processing {file}...\", end='')\n",
    "        path = f\"Data/{file}\"\n",
    "        \n",
    "        # Load the file data\n",
    "        temp_df = pd.read_csv(path)\n",
    "        temp_df = cols_convert(temp_df)\n",
    "        \n",
    "        # Create column names for 12, 24, and 36 months prior\n",
    "        feature_name = file[:-4]  # Remove .csv extension\n",
    "        colname1 = f\"{feature_name} 12 months prior\"\n",
    "        colname2 = f\"{feature_name} 24 months prior\"\n",
    "        colname3 = f\"{feature_name} 36 months prior\"\n",
    "\n",
    "        # Initialize columns with NaN values\n",
    "        result_df[[colname1, colname2, colname3]] = np.nan\n",
    "                \n",
    "        # Process each target year\n",
    "        for year in years:\n",
    "            # Define the dates we need (December 31st of each prior year)\n",
    "            date1 = f\"{year - 1}-12-31\"  # 12 months prior\n",
    "            date2 = f\"{year - 2}-12-31\"  # 24 months prior\n",
    "            date3 = f\"{year - 3}-12-31\"  # 36 months prior\n",
    "\n",
    "            # Get companies for the current year\n",
    "            year_companies = result_df[result_df['YEAR'] == year]\n",
    "\n",
    "            # Extract data for these companies\n",
    "            company_data = temp_df[temp_df['TICKER'].isin(year_companies['TICKER'])]\n",
    "\n",
    "            # Select relevant columns\n",
    "            if date1 in company_data.columns and date2 in company_data.columns and date3 in company_data.columns:\n",
    "                selected_data = company_data[['TICKER', date1, date2, date3]]\n",
    "                \n",
    "                # Rename the columns\n",
    "                selected_data.columns = ['TICKER', colname1, colname2, colname3]\n",
    "                \
