{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading our data\n",
    "We will be working with \"institutional strength\" stock level data through this module. The stock universe is known as the All Countries World Index (ACWI). These stocks are equities drawn from developed (DM) and emerging markets (EM) and represent around 6000 investable equities with data drawn from the year 2000 through to the end of 2020. This is considered to be a very broad universe of stocks and encompasses the full range of sectors and companies from around 50 countries. We will be using a number of critical features associated with each stock which are drawn from exchange level data, such as pricing, fundamentals, from financial reporting, and sentiment scoring drawn from new-flow. \n",
    "\n",
    "PLEASE NOTE THAT THE EQUITIES HAVE BEEN ANONYMISED AND NOTE THE LICENSING OF THIS DATASET PROHIBITS DISTIBUTION OR USE OF THIS DATA BEYOND THIS COURSE.\n",
    "\n",
    "This dataset will be used to take you through the process of loading, pre-processing and then using various learners and techniques to build investment models, to allow us to select the \"best\" stocks to generate stronger return characteristics than simply investing in the index would give us.\n",
    "\n",
    "The file we will be working with is named ```ACWI fundamental data.xlsx```. If one was to load this file in excel then one would find financial data on around 6000 companies spread across a number of different worksheets. \n",
    "NB: Files in the XLSX format can be very slow to work with in python so it is normally a good idea to convert the worksheets to separate CSV files. In this notebook, we will see how this can be done automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas ... lovely and yet horrid\n",
    "We will be using Pandas for ease in this module which makes operations on smaller data-sets easy and generic. However, before you engineer your own investment pipeline with Pandas, bear in mind that in the real world it is not advised. Remember, anything that looks like SQL should live on a server, not on a client machine. Better to use an enterprise strength SQL back end to do enterprise back end stuff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package for working with tabular data\n",
    "import pandas as pd \n",
    "\n",
    "# package for timing runtime\n",
    "import time\n",
    "\n",
    "# package for navigating the operating system\n",
    "import os       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by loading ```ACWI fundamental data.xlsx```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ACWI fundamental data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-22d1b69fdee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ACWI fundamental data.xlsx\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mxls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"It took %s seconds to load the .xlsx file.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1072\u001b[0m                     \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(path, content, storage_options)\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mcontent_or_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m    950\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     ) as handle:\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ACWI fundamental data.xlsx'"
     ]
    }
   ],
   "source": [
    "path = \"ACWI fundamental data.xlsx\"\n",
    "start_time = time.time()\n",
    "xls = pd.ExcelFile(path)\n",
    "print(\"It took %s seconds to load the .xlsx file.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my machine, it took 635 seconds to load the data. Let us look at the worksheet names in the XLSX file. Let us look at the worksheets in ```xls```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TotalReturn_BaseCCY\n",
      "1 EPS\n",
      "2 GroupRank_NPL_Loans_egSector\n",
      "3 Mkt_Beta_2yrs\n",
      "4 NI_Sales\n",
      "5 Diag SentimentNews\n",
      "6 Diag EPSGrowth3yrAverage_Rothko\n",
      "7 OperationalLev_USD\n",
      "8 Rev_Quality\n",
      "9 Diag FreeCashFlowpershare\n",
      "10 EBITDA_SALES\n",
      "11 Diag TotalYield\n",
      "12 Diag DebtToEquity\n",
      "13 Diag PE\n",
      "14 Diag EPS\n",
      "15 Beta_DnSide_24m\n",
      "16 GroupRank_Diag FreeCashFlowpers\n",
      "17 Diag ROE\n"
     ]
    }
   ],
   "source": [
    "for i, sheet_name in enumerate(xls.sheet_names):\n",
    "    print(i, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 18 worksheets. We will convert these worksheets into separate CSV files, and store them in a folder named ```Data```.\n",
    "Please see the data_dictionary.md to understand more about the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Data/TotalReturn_BaseCCY.csv ... DONE\n",
      "Saving Data/EPS.csv ... DONE\n",
      "Saving Data/GroupRank_NPL_Loans_egSector.csv ... DONE\n",
      "Saving Data/Mkt_Beta_2yrs.csv ... DONE\n",
      "Saving Data/NI_Sales.csv ... DONE\n",
      "Saving Data/Diag SentimentNews.csv ... DONE\n",
      "Saving Data/Diag EPSGrowth3yrAverage_Rothko.csv ... DONE\n",
      "Saving Data/OperationalLev_USD.csv ... DONE\n",
      "Saving Data/Rev_Quality.csv ... DONE\n",
      "Saving Data/Diag FreeCashFlowpershare.csv ... DONE\n",
      "Saving Data/EBITDA_SALES.csv ... DONE\n",
      "Saving Data/Diag TotalYield.csv ... DONE\n",
      "Saving Data/Diag DebtToEquity.csv ... DONE\n",
      "Saving Data/Diag PE.csv ... DONE\n",
      "Saving Data/Diag EPS.csv ... DONE\n",
      "Saving Data/Beta_DnSide_24m.csv ... DONE\n",
      "Saving Data/GroupRank_Diag FreeCashFlowpers.csv ... DONE\n",
      "Saving Data/Diag ROE.csv ... DONE\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"Data\" # name of the folder that we store the CSV files in\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"Data\") # make a folder named Data\n",
    "except:\n",
    "    pass # pass if the folder already exists\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    path = \"Data/\" + sheet_name + \".csv\" # path to where we want to save the CSV file\n",
    "    print(\"Saving \" + path + \" ...\", end='')\n",
    "    \n",
    "    # load the worksheet into a dataframe\n",
    "    df = pd.read_excel(\n",
    "        xls, \n",
    "        sheet_name, \n",
    "        skiprows = 8 # the data does not start until after row 8\n",
    "    )\n",
    "    \n",
    "    # convert the date column names into a consistent format\n",
    "    dates = df.columns[4:]\n",
    "    dates = pd.to_datetime(dates)\n",
    "    dates = list(dates.strftime('%Y-%m-%d')) # convert the dates to the form YYYY-MM-DD\n",
    "    df.columns = list(df.columns[:4]) + dates\n",
    "    \n",
    "    # save the worksheet as a CSV file in the data folder\n",
    "    df.to_csv(\n",
    "        path, \n",
    "        index=False # prevent the index column being saved\n",
    "    )\n",
    "    print(\" DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ```os.listdir()``` function to list the files in the ```Data``` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beta_DnSide_24m.csv',\n",
       " 'Diag DebtToEquity.csv',\n",
       " 'Diag EPS.csv',\n",
       " 'Diag EPSGrowth3yrAverage_Rothko.csv',\n",
       " 'Diag FreeCashFlowpershare.csv',\n",
       " 'Diag PE.csv',\n",
       " 'Diag ROE.csv',\n",
       " 'Diag SentimentNews.csv',\n",
       " 'Diag TotalYield.csv',\n",
       " 'EBITDA_SALES.csv',\n",
       " 'EPS.csv',\n",
       " 'GroupRank_Diag FreeCashFlowpers.csv',\n",
       " 'GroupRank_NPL_Loans_egSector.csv',\n",
       " 'Mkt_Beta_2yrs.csv',\n",
       " 'NI_Sales.csv',\n",
       " 'OperationalLev_USD.csv',\n",
       " 'Rev_Quality.csv',\n",
       " 'TotalReturn_BaseCCY.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see how fast it is to load these CSV files compared to the original XLSX file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta_DnSide_24m.csv loading DONE\n",
      "Diag DebtToEquity.csv loading DONE\n",
      "Diag EPS.csv loading DONE\n",
      "Diag EPSGrowth3yrAverage_Rothko.csv loading DONE\n",
      "Diag FreeCashFlowpershare.csv loading DONE\n",
      "Diag PE.csv loading DONE\n",
      "Diag ROE.csv loading DONE\n",
      "Diag SentimentNews.csv loading DONE\n",
      "Diag TotalYield.csv loading DONE\n",
      "EBITDA_SALES.csv loading DONE\n",
      "EPS.csv loading DONE\n",
      "GroupRank_Diag FreeCashFlowpers.csv loading DONE\n",
      "GroupRank_NPL_Loans_egSector.csv loading DONE\n",
      "Mkt_Beta_2yrs.csv loading DONE\n",
      "NI_Sales.csv loading DONE\n",
      "OperationalLev_USD.csv loading DONE\n",
      "Rev_Quality.csv loading DONE\n",
      "TotalReturn_BaseCCY.csv loading DONE\n",
      "It took 9.068223237991333 seconds to load the .csv files.\n"
     ]
    }
   ],
   "source": [
    "worksheets = os.listdir('Data')\n",
    "\n",
    "start_time = time.time()\n",
    "for worksheet in worksheets:\n",
    "    print(worksheet + \" loading \", end='')\n",
    "    df = pd.read_csv(\"Data/\" + worksheet)\n",
    "    print(\"DONE\")\n",
    "print(\"It took %s seconds to load the .csv files.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took 9 seconds to load all of the CSV files. Let us take a look at one of the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>2020-09-20</th>\n",
       "      <th>2020-08-31</th>\n",
       "      <th>2020-07-31</th>\n",
       "      <th>2020-06-30</th>\n",
       "      <th>2020-05-31</th>\n",
       "      <th>2020-04-30</th>\n",
       "      <th>...</th>\n",
       "      <th>2000-10-31</th>\n",
       "      <th>2000-09-30</th>\n",
       "      <th>2000-08-31</th>\n",
       "      <th>2000-07-31</th>\n",
       "      <th>2000-06-30</th>\n",
       "      <th>2000-05-31</th>\n",
       "      <th>2000-04-30</th>\n",
       "      <th>2000-03-31</th>\n",
       "      <th>2000-02-29</th>\n",
       "      <th>2000-01-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen Asset Management PLC</td>\n",
       "      <td>1</td>\n",
       "      <td>Financials</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045730</td>\n",
       "      <td>-0.120105</td>\n",
       "      <td>0.207501</td>\n",
       "      <td>-0.016259</td>\n",
       "      <td>0.201910</td>\n",
       "      <td>-0.061498</td>\n",
       "      <td>-0.226854</td>\n",
       "      <td>0.248221</td>\n",
       "      <td>0.435955</td>\n",
       "      <td>0.224755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbey National Plc</td>\n",
       "      <td>2</td>\n",
       "      <td>Financials</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038953</td>\n",
       "      <td>0.095348</td>\n",
       "      <td>0.104281</td>\n",
       "      <td>-0.062044</td>\n",
       "      <td>-0.100452</td>\n",
       "      <td>0.161520</td>\n",
       "      <td>-0.130285</td>\n",
       "      <td>0.221048</td>\n",
       "      <td>-0.072973</td>\n",
       "      <td>-0.241147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chubb Plc</td>\n",
       "      <td>3</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>-0.129013</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>-0.062093</td>\n",
       "      <td>0.026172</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.119904</td>\n",
       "      <td>0.222242</td>\n",
       "      <td>0.026770</td>\n",
       "      <td>-0.111193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kidde Plc</td>\n",
       "      <td>4</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amec Foster Wheeler plc</td>\n",
       "      <td>5</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.223598</td>\n",
       "      <td>0.179246</td>\n",
       "      <td>-0.150297</td>\n",
       "      <td>0.251863</td>\n",
       "      <td>-0.096557</td>\n",
       "      <td>0.234714</td>\n",
       "      <td>-0.331340</td>\n",
       "      <td>-0.077761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NAME  TICKER                  SECTOR  \\\n",
       "0  Aberdeen Asset Management PLC       1              Financials   \n",
       "1             Abbey National Plc       2              Financials   \n",
       "2                      Chubb Plc       3             Industrials   \n",
       "3                      Kidde Plc       4  Consumer Discretionary   \n",
       "4        Amec Foster Wheeler plc       5             Industrials   \n",
       "\n",
       "          COUNTRY  2020-09-20  2020-08-31  2020-07-31  2020-06-30  2020-05-31  \\\n",
       "0  United Kingdom         NaN         NaN         NaN         NaN         NaN   \n",
       "1  United Kingdom         NaN         NaN         NaN         NaN         NaN   \n",
       "2  United Kingdom         NaN         NaN         NaN         NaN         NaN   \n",
       "3  United Kingdom         NaN         NaN         NaN         NaN         NaN   \n",
       "4  United Kingdom         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   2020-04-30  ...  2000-10-31  2000-09-30  2000-08-31  2000-07-31  \\\n",
       "0         NaN  ...    0.045730   -0.120105    0.207501   -0.016259   \n",
       "1         NaN  ...    0.038953    0.095348    0.104281   -0.062044   \n",
       "2         NaN  ...    0.001878   -0.129013    0.024722   -0.062093   \n",
       "3         NaN  ...         NaN         NaN         NaN         NaN   \n",
       "4         NaN  ...   -0.000716    0.034200    0.223598    0.179246   \n",
       "\n",
       "   2000-06-30  2000-05-31  2000-04-30  2000-03-31  2000-02-29  2000-01-31  \n",
       "0    0.201910   -0.061498   -0.226854    0.248221    0.435955    0.224755  \n",
       "1   -0.100452    0.161520   -0.130285    0.221048   -0.072973   -0.241147  \n",
       "2    0.026172    0.031064    0.119904    0.222242    0.026770   -0.111193  \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "4   -0.150297    0.251863   -0.096557    0.234714   -0.331340   -0.077761  \n",
       "\n",
       "[5 rows x 253 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/TotalReturn_BaseCCY.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CSV contains the monthly return data of around 6000 companies from 2000 to 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
